{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import namedtuple, OrderedDict\n",
    "import datetime\n",
    "import ujson\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import math\n",
    "import time\n",
    "import gzip\n",
    "\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "LOGS = './logs/'\n",
    "Window = namedtuple('Window', ['pid', 'name', 'start_time', 'last_update', 'focus_time', 'exe', 'cmd'])\n",
    "Event = namedtuple('Event', ['time', 'category', 'text', 'index'])\n",
    "\n",
    "def load(file):\n",
    "    if file.split('.')[-1] == 'gz':\n",
    "        with gzip.open(file) as f:\n",
    "            data = ujson.loads(f.read().decode('utf-8'))\n",
    "    else:\n",
    "        with open(file, encoding='utf-8') as f:\n",
    "            data = ujson.load(f)\n",
    "    return [Window(*v) for v in data]\n",
    "\n",
    "def load_data():\n",
    "    files = {file : os.path.getctime(os.path.join(LOGS, file)) for file in os.listdir(LOGS)}\n",
    "    data = None\n",
    "\n",
    "    for file in files:\n",
    "        day = load(os.path.join(LOGS, file))\n",
    "        day = pd.DataFrame.from_records(day, columns=Window._fields)\n",
    "        day['start_time'] = day['start_time'].apply(lambda x : pd.Timestamp(x))\n",
    "        day['last_update'] = day['last_update'].apply(lambda x : pd.Timestamp(x))\n",
    "        day['focus_time'] = day['focus_time'].apply(lambda x : pd.Timedelta(x))\n",
    "        day['boot'] = day['start_time'].min()\n",
    "        day['start_time'] = day['last_update'] - day['focus_time']\n",
    "        data = pd.concat([data, day])\n",
    "        \n",
    "    if data is None:    \n",
    "        data['category'] = merge(data['name'].apply(lambda x: categorize(x, categories_name)).values, \n",
    "                                 data['exe'].apply(lambda x: categorize(x, categories_exe)).values,\n",
    "                                 data['exe'].str.split('\\\\').apply(lambda x: x[-1]).values)\n",
    "    return data\n",
    "\n",
    "def reindex(colname):\n",
    "    data.index = data[colname]\n",
    "    data.sort_index(inplace=True, ascending=False)\n",
    "    return data\n",
    "\n",
    "def expand_multi_dict(key_val_pair):\n",
    "    ret = []\n",
    "    for item in key_val_pair:\n",
    "        if type(item[0]) != list:\n",
    "            ret.append(item)\n",
    "        else:\n",
    "            for sub_item in item[0]:\n",
    "                ret.append((sub_item, item[1]))\n",
    "    return ret\n",
    "\n",
    "def categorize(x, dictionary):\n",
    "    for k, v in dictionary.items():\n",
    "        if k.lower() in x.lower():\n",
    "            return v\n",
    "        \n",
    "def merge(*lists):\n",
    "    ret = lists[0]\n",
    "    for l in lists[:-1]:\n",
    "        assert len(l) == len(lists[-1])\n",
    "    for i in range(len(lists[0])):\n",
    "        for l in lists:\n",
    "            if l[i]:\n",
    "                ret[i] = l[i]\n",
    "                break\n",
    "    return ret\n",
    "\n",
    "def time_ticks(x, pos):\n",
    "    return str(datetime.timedelta(milliseconds=x*3.6))\n",
    "def label_ticks(y, pos):\n",
    "    global positions_sequence\n",
    "    return positions_sequence[int(round(y))]\n",
    "def date_boot_ticks(x, pos):\n",
    "    global boot_time_round\n",
    "    return (boot_time_round + datetime.timedelta(milliseconds=x*3.6)).strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# categorizes data points by window_name (first match)\n",
    "# format: (list of window_names : category)\n",
    "categories_name = OrderedDict(expand_multi_dict([\n",
    "    ('- TODO', 'todo'),\n",
    "    (['notebook', 'jupyter', 'ipython', 'python', 'hackerrank', 'topcoder', 'codingame', 'Focus'], 'python'),\n",
    "    ('git', 'git'),\n",
    "    (['Wiki'], 'wiki'),\n",
    "    ('Stack Overflow', 'stackoverflow'),\n",
    "    ('Google Search', 'google'),\n",
    "    ('documentation', 'docs'),\n",
    "    (['.png', '.jpg', 'imgur', 'gif', 'gifv'], 'img'),\n",
    "    ('excel', 'excel'),\n",
    "    (['reddit'], 'reddit'),\n",
    "    (['AFK', 'Program Manager'], 'afk'),\n",
    "    ('Twitch','twitch'),\n",
    "    ('YouTube','youtube'),\n",
    "    ('https://', 'loading'),\n",
    "    (['- 360Chrome', 'coolnovo', 'chrome', 'firefox', 'opera', 'vivaldi'], 'browser'),\n",
    "    ('- Clover','files'),\n",
    "]))\n",
    "\n",
    "# categorizes data points by exe_path\n",
    "# format: (list of exe_paths : category)\n",
    "categories_exe = OrderedDict(expand_multi_dict([\n",
    "    ('chrome.exe' , 'browser'),\n",
    "    ('pycharm' , 'python'),\n",
    "    ('Spotify.exe' , 'spotify'),\n",
    "    (['ConEmu64.exe', 'cmd.exe'], 'console'),\n",
    "    ('notepad++.exe', 'notepad'),\n",
    "    ('taskmgr.exe', 'taskmgr'),\n",
    "    ('clover.exe', 'files'),\n",
    "    ('wox.exe', 'wox'),\n",
    "    ('excel.exe', 'excel'),\n",
    "    ('calc.exe', 'calculator'),           \n",
    "    (r'/games/', 'games'),\n",
    "    ('explorer.exe', 'files'),\n",
    "]))\n",
    "\n",
    "CUTOFF = 20*1e6/60  # display categories with at least 20 minutes total focus time\n",
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_top_categories(data, category_count=None):\n",
    "    d = data.groupby('category')['focus_time'].sum().apply(lambda x: x / np.timedelta64(1,'ms')/3.6)\n",
    "    d = d.sort_values(ascending=False)[:category_count] if category_count else d[d>CUTOFF].sort_values(ascending=False)\n",
    "    category_count = len(d.index)\n",
    "    plt.figure(figsize=(20,6))\n",
    "    ax = sns.barplot(d.values, d.index, orient='h', palette=sns.color_palette('husl', category_count))\n",
    "    ax.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(time_ticks))\n",
    "#plot_top_categories(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_top_by_date(data):\n",
    "    d = data.groupby(['category', 'boot'])['focus_time'].sum().apply(lambda x: x / np.timedelta64(1,'ms')/3.6)\n",
    "    d = d.sort_values(ascending=False).unstack(level=1)\n",
    "\n",
    "    d['sum'] = d.sum(1)\n",
    "    d = d[d['sum'] > CUTOFF].sort_values('sum', ascending=True)\n",
    "    del d['sum']\n",
    "    global positions_sequence\n",
    "    positions_sequence = list(d.index)\n",
    "    sns.set_palette('colorblind')\n",
    "    ax = d.plot.barh(stacked=True, figsize=(20,6), width=0.8, fontsize=13, legend=False)\n",
    "    ax.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(time_ticks))\n",
    "#plot_top_by_date(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_category_by_day(data, exe_name):\n",
    "    d = data.groupby(['category', 'boot'])['focus_time'].sum().apply(lambda x: x / np.timedelta64(1,'ms')/3.6)\n",
    "    d = d.sort_values(ascending=False).unstack(level=1)\n",
    "\n",
    "    d['sum'] = d.sum(1)\n",
    "    d = d[d['sum'] > CUTOFF].sort_values('sum', ascending=True)\n",
    "    del d['sum']\n",
    "    \n",
    "    ax = ((d.query(\"category == '{}'\".format(exe_name)).dropna(1).T)).plot()\n",
    "    ax.yaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(time_ticks))\n",
    "#plot_category_by_day(data, 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_timeline_by_category_time(data, categories):\n",
    "    def date_ticks_from_days(x, pos):\n",
    "        print(x)\n",
    "        return pd.Timestamp(x).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    categories = data.groupby('category')['focus_time'].sum().apply(lambda x: x / np.timedelta64(1,'ms')/3.6).sort_values(ascending=False).head(HEAD).index\n",
    "    d = data.groupby(['category', 'boot']).focus_time.sum().unstack(0)\n",
    "    ax = d[categories].resample('D').sum().fillna(pd.Timedelta(0)).apply(lambda x: x / np.timedelta64(1,'ms') / 3.6).plot(figsize=(27,7), x_compat=False)\n",
    "    ax.yaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(time_ticks))\n",
    "    ax.xaxis.grid(True, which=\"minor\")\n",
    "#plot_timeline_by_category_time(data, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_day_sequence_chart(category_count):\n",
    "    def add_event_vline(event):\n",
    "        pos = (event.time - boot_time_round) / np.timedelta64(1, 'ms') / 3.6\n",
    "        y = -1.3\n",
    "        plt.axvline(pos, color=palette[positions_sequence.index(event.category)])\n",
    "        plt.text(pos, -1-0.7*(event.index%3), event.text, rotation=0, fontsize=13)\n",
    "\n",
    "    files = {file : os.path.getctime(os.path.join(LOGS, file)) for file in os.listdir(LOGS)}\n",
    "    today = (dt.datetime.fromtimestamp(files[sorted(files.keys())[-1]]) - pd.Timedelta('6 hours')).date()\n",
    "    day = sum([load(os.path.join(LOGS, k)) for k, v in files.items() if (dt.datetime.fromtimestamp(v) - pd.Timedelta('6 hours')).date() == today], [])\n",
    "    day = pd.DataFrame.from_records(day, columns=Window._fields)\n",
    "    day['focus_time'] = day['focus_time'].apply(lambda x : pd.Timedelta(x))\n",
    "    day['start_time'] = day['start_time'].apply(lambda x : pd.Timestamp(x))\n",
    "    day['last_update'] = day['last_update'].apply(lambda x : pd.Timestamp(x))\n",
    "    day['category'] = merge(day['name'].apply(lambda x: categorize(x, categories_name)).values, \n",
    "                             day['exe'].apply(lambda x: categorize(x, categories_exe)).values,\n",
    "                             day['exe'].str.split('\\\\').apply(lambda x: x[-1]).values)\n",
    "    global positions_sequence\n",
    "    positions_sequence = list(reversed(list(day.groupby('category')['focus_time'].sum().sort_values(ascending=False)[:category_count].index)))\n",
    "    \n",
    "    data = day.groupby(['pid', 'name', 'start_time']).agg({'focus_time' : sum, 'last_update' : max, 'exe' : max, 'cmd': max, 'category':max}).reset_index().sort_values('focus_time', ascending=False)\n",
    "    d = day.set_index('category')[['focus_time', 'last_update']]\n",
    "    d['start_time'] = d['last_update'] - d['focus_time']\n",
    "    d['focus_time'] = d['focus_time'].apply(lambda x: x / np.timedelta64(1,'ms') / 3.6)\n",
    "    d = d.sort_values('start_time')\n",
    "    boot_time = day['start_time'].min()\n",
    "    global boot_time_round\n",
    "    boot_time_round = boot_time.replace(minute=0, second=0)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(27,7))\n",
    "    ax = fig.add_subplot(111)\n",
    "    palette = list(reversed(sns.color_palette('husl', category_count)))\n",
    "    pad = 60*1000/3.6  # 60sec = expand length of event for quick events\n",
    "    stitch = 60*1000/3.6 # 60sec = events with a (gap < stitch) become one\n",
    "\n",
    "    # stitching\n",
    "    d2 = []\n",
    "    for category in set(d.index):\n",
    "        group = d[d.index == category].reset_index()\n",
    "        stime = group.ix[0].start_time\n",
    "        ltime = group.ix[0].last_update\n",
    "        lg = len(group)\n",
    "        if lg==1:\n",
    "            d2.append(pd.Series(index=['start_time', 'last_update', 'focus_time'], name=category,\n",
    "                     data=[stime, ltime, (ltime - stime) / np.timedelta64(1,'ms') / 3.6]))\n",
    "        group['gap'] = (group['start_time'] - group.shift(1)['last_update']) / np.timedelta64(1,'ms') / 3.6\n",
    "        for row in range(1, lg+1):\n",
    "            if row==lg or (group.ix[row].gap > stitch and row < lg):\n",
    "                d2.append(pd.Series(index=['start_time', 'last_update', 'focus_time'], name=category,\n",
    "                                         data=[stime, group.ix[row-1].last_update, (group.ix[row-1].last_update - stime) / np.timedelta64(1,'ms') / 3.6]))\n",
    "                if row < lg:\n",
    "                    stime = group.ix[row].start_time\n",
    "    d2 = pd.DataFrame(d2)\n",
    "\n",
    "    for row in range(len(d2)):\n",
    "        if d2.index[row] in positions_sequence:\n",
    "            # pad to the left and to the right to reduce noise\n",
    "            category = positions_sequence.index(d2.index[row])\n",
    "            ax.barh(positions_sequence.index(d2.index[row]), d2.ix[row, 'focus_time']+pad, height=.8, align='center', color=palette[category],\n",
    "                    left=(d2.ix[row, 'start_time'] - boot_time_round) / np.timedelta64(1,'ms') / 3.6 - pad, edgecolor = 'none')\n",
    "\n",
    "    ax.xaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(date_boot_ticks))\n",
    "    ax.yaxis.set_major_formatter(matplotlib.ticker.FuncFormatter(label_ticks))\n",
    "    ax.xaxis.set_minor_locator(matplotlib.ticker.AutoMinorLocator(6))\n",
    "    ax.tick_params(labelright=True, labeltop=True)\n",
    "    ax.grid(b=True, which='minor', color='w', linewidth=0.7)\n",
    "    ax.grid(b=True, which='major', color='w', linewidth=1.5)\n",
    "    ax.set_yticks(range(len(positions_sequence)))\n",
    "    ax.set_yticklabels(positions_sequence)\n",
    "    ax.set_ylim(-2.7, len(positions_sequence))\n",
    "\n",
    "    # axvlines\n",
    "    event_delta = pd.Timedelta('10min')\n",
    "    for i, (_, event_row) in enumerate(data[data['category'] == 'todo'].sort_values('last_update').iterrows()):\n",
    "        if event_row['last_update'] > pd.Timestamp('2016-05-28 17:00'):\n",
    "            event_time = event_row['last_update'] - event_row['focus_time'] \n",
    "            category = day[(event_time - event_delta < day['last_update'] - day['focus_time']) & (day['last_update'] - day['focus_time'] < event_time + event_delta) | \n",
    "                (event_time - event_delta < day['last_update']) & (day['last_update'] < event_time + event_delta) |\n",
    "                (day['last_update'] - day['focus_time'] < event_time) & (event_time < day['last_update'])].groupby('category')['focus_time'].sum().idxmax()        \n",
    "            add_event_vline(Event(event_time, category, event_row['name'].split('- TODO')[0], i))\n",
    "    plt.show()\n",
    "#plot_day_sequence_chart(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}